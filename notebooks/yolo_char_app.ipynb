{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2999a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7871\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7871/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 128x640 2 0s, 1 1, 2 4s, 1 6, 1 8, 1 L, 1 T, 243.1ms\n",
      "Speed: 2.1ms preprocess, 243.1ms inference, 1.7ms postprocess per image at shape (1, 3, 128, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gnz/GitHub/yolo11_container/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 128x640 1 1, 3 2s, 1 4, 2 8s, 1 S, 1 U, 323.3ms\n",
      "Speed: 7.2ms preprocess, 323.3ms inference, 2.8ms postprocess per image at shape (1, 3, 128, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gnz/GitHub/yolo11_container/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 1, 1 5, 675.6ms\n",
      "Speed: 78.1ms preprocess, 675.6ms inference, 15.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gnz/GitHub/yolo11_container/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 1, 1 5, 313.8ms\n",
      "Speed: 12.4ms preprocess, 313.8ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gnz/GitHub/yolo11_container/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 160x640 1 0, 1 1, 1 2, 1 4, 2 5s, 1 7, 1 9, 1 J, 1 L, 1 R, 1 T, 1 U, 609.0ms\n",
      "Speed: 132.7ms preprocess, 609.0ms inference, 8.0ms postprocess per image at shape (1, 3, 160, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gnz/GitHub/yolo11_container/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import easyocr\n",
    "\n",
    "# Cargar modelo YOLO\n",
    "char_model = YOLO(\"/home/gnz/GitHub/yolo11_container/YOLO_Characters/Character_YOLO_container_finetune_large/weights/best.pt\")\n",
    "\n",
    "# Inicializar EasyOCR\n",
    "reader = easyocr.Reader(['en','es']) \n",
    "\n",
    "def predict(image):\n",
    "    # 1. Detección\n",
    "    results = char_model.predict(image, conf=0.25)[0]\n",
    "\n",
    "    # 2. Imagen con bounding boxes\n",
    "    img_with_boxes = results.plot()\n",
    "    img_with_boxes_pil = Image.fromarray(img_with_boxes)\n",
    "\n",
    "    # 3. Extraer detecciones en lista\n",
    "    detections = []\n",
    "    for box, cls, conf in zip(results.boxes.xyxy, results.boxes.cls, results.boxes.conf):\n",
    "        x1, y1, x2, y2 = map(int, box)\n",
    "        detections.append({\n",
    "            \"coords\": (x1, y1, x2, y2),\n",
    "            \"class_idx\": int(cls),\n",
    "            \"confidence\": float(conf)\n",
    "        })\n",
    "\n",
    "    # 4. Ordenar por coordenada x (izquierda a derecha)\n",
    "    detections = sorted(detections, key=lambda d: d[\"coords\"][0])\n",
    "\n",
    "    crops = []\n",
    "    ocr_results = []\n",
    "    yolo_char_concat = \"\"\n",
    "    ocr_concat_char_yolo = \"\"\n",
    "\n",
    "    # 5. Recorrer detecciones ordenadas\n",
    "    for det in detections:\n",
    "        x1, y1, x2, y2 = det[\"coords\"]\n",
    "        crop = image.crop((x1, y1, x2, y2))\n",
    "        crops.append(crop)\n",
    "\n",
    "        # YOLO char\n",
    "        yolo_char = results.names[det[\"class_idx\"]]\n",
    "        yolo_char_concat += yolo_char\n",
    "\n",
    "        # OCR por crop\n",
    "        ocr_out = reader.readtext(np.array(crop))\n",
    "        text = ocr_out[0][1] if len(ocr_out) > 0 else \"\"\n",
    "        ocr_concat_char_yolo += text\n",
    "\n",
    "        # Guardar info sin coordenadas\n",
    "        ocr_results.append({\n",
    "            \"class\": yolo_char,\n",
    "            \"confidence\": det[\"confidence\"],\n",
    "            \"ocr\": text\n",
    "        })\n",
    "\n",
    "    # OCR en imagen completa\n",
    "    ocr_full_out = reader.readtext(np.array(image))\n",
    "    output_ocr_id = \"\".join([txt[1] for txt in ocr_full_out]) if len(ocr_full_out) > 0 else \"\"\n",
    "\n",
    "    # Construir JSON final\n",
    "    final_output = {\n",
    "        \"detailed_results\": ocr_results,\n",
    "        \"output_yolo_char\": yolo_char_concat,\n",
    "        \"ocr_concat_char_yolo\": ocr_concat_char_yolo,\n",
    "        \"output_ocr_id\": output_ocr_id\n",
    "    }\n",
    "\n",
    "    return img_with_boxes_pil, crops, final_output\n",
    "\n",
    "\n",
    "# Interfaz Gradio\n",
    "demo = gr.Interface(\n",
    "    fn=predict,\n",
    "    inputs=gr.Image(type=\"pil\"),\n",
    "    outputs=[\n",
    "        gr.Image(type=\"pil\", label=\"Detección IDs\"),\n",
    "        gr.Gallery(label=\"Crops ordenados\", columns=5, height=\"auto\"),     \n",
    "        gr.JSON(label=\"Resultados detallados y concatenación\")\n",
    "    ],\n",
    "    title=\"Container Character Classification\",\n",
    "    description=\"Detecta caracteres de contenedores y los concatena en orden.\"\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507e1342",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 128x640 2 0s, 1 1, 2 4s, 1 6, 1 8, 1 L, 1 T, 51.7ms\n",
      "Speed: 0.8ms preprocess, 51.7ms inference, 0.8ms postprocess per image at shape (1, 3, 128, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gnz/GitHub/yolo11_container/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gnz/GitHub/yolo11_container/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 128x640 2 0s, 1 1, 2 4s, 1 6, 1 8, 1 L, 1 T, 201.2ms\n",
      "Speed: 0.8ms preprocess, 201.2ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "0: 96x640 2 0s, 1 1, 2 2s, 3 8s, 1 M, 1 U, 63.8ms\n",
      "Speed: 1.1ms preprocess, 63.8ms inference, 1.1ms postprocess per image at shape (1, 3, 96, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gnz/GitHub/yolo11_container/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 128x640 2 0s, 3 4s, 1 6, 1 8, 1 C, 61.0ms\n",
      "Speed: 1.9ms preprocess, 61.0ms inference, 0.6ms postprocess per image at shape (1, 3, 128, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gnz/GitHub/yolo11_container/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 320x640 1 1, 132.2ms\n",
      "Speed: 1.5ms preprocess, 132.2ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gnz/GitHub/yolo11_container/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gnz/GitHub/yolo11_container/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 2, 1 3, 1 5, 1 6, 3 7s, 1 B, 1 M, 1 O, 1 U, 201.3ms\n",
      "Speed: 2.8ms preprocess, 201.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 192x640 1 0, 1 2, 2 3s, 2 5s, 1 7, 1 E, 1 M, 2 Ts, 1 U, 918.8ms\n",
      "Speed: 215.0ms preprocess, 918.8ms inference, 27.7ms postprocess per image at shape (1, 3, 192, 640)\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import easyocr\n",
    "\n",
    "# Cargar modelo YOLO\n",
    "char_model = YOLO(\"/home/gnz/GitHub/yolo11_container/YOLO_Characters/Character_YOLO_container_finetune_large/weights/best.pt\")\n",
    "\n",
    "# Inicializar EasyOCR\n",
    "reader = easyocr.Reader(['en','es']) \n",
    "\n",
    "\n",
    "def predict(image):\n",
    "    # ---------------------------\n",
    "    # 1. OCR sobre imagen completa\n",
    "    # ---------------------------\n",
    "    ocr_full = reader.readtext(np.array(image), detail=0)  # lista de strings\n",
    "\n",
    "    # ---------------------------\n",
    "    # 2. Detección con YOLO\n",
    "    # ---------------------------\n",
    "    results = char_model.predict(image, conf=0.25)[0]  # Tomamos el primer batch\n",
    "\n",
    "    # Imagen con bounding boxes\n",
    "    img_with_boxes = results.plot()\n",
    "    img_with_boxes_pil = Image.fromarray(img_with_boxes)\n",
    "\n",
    "    crops = []\n",
    "    ocr_results_crops = []\n",
    "    classes_detected = []\n",
    "\n",
    "    # ---------------------------\n",
    "    # 3. Recorrer cada detección y aplicar OCR en crops\n",
    "    # ---------------------------\n",
    "    for box, cls, conf in zip(results.boxes.xyxy, results.boxes.cls, results.boxes.conf):\n",
    "        x1, y1, x2, y2 = map(int, box)\n",
    "        crop = image.crop((x1, y1, x2, y2))\n",
    "        crops.append(crop)\n",
    "\n",
    "        # OCR en el crop\n",
    "        ocr_text_crop = reader.readtext(np.array(crop), detail=0)\n",
    "\n",
    "        class_name = results.names[int(cls)]\n",
    "        classes_detected.append(class_name)\n",
    "\n",
    "        ocr_results_crops.append({\n",
    "            \"class\": class_name,\n",
    "            \"confidence\": float(conf),\n",
    "            \"ocr_text\": ocr_text_crop if ocr_text_crop else None\n",
    "        })\n",
    "\n",
    "    # ---------------------------\n",
    "    # 4. Resultado final como texto\n",
    "    # ---------------------------\n",
    "    resumen = \"📌 **Resumen detecciones**\\n\\n\"\n",
    "    resumen += f\"- Clases detectadas por YOLO: {', '.join(classes_detected) if classes_detected else 'Ninguna'}\\n\"\n",
    "    resumen += f\"- OCR en imagen completa: {', '.join(ocr_full) if ocr_full else 'No se detectó texto'}\\n\"\n",
    "\n",
    "    return (\n",
    "        img_with_boxes_pil,   # imagen con bounding boxes\n",
    "        crops,                # crops individuales\n",
    "        ocr_results_crops,    # JSON con clases + OCR en crops\n",
    "        ocr_full,             # OCR en imagen completa (lista de strings)\n",
    "        resumen               # resumen final en texto\n",
    "    )\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 5. Interfaz Gradio\n",
    "# ---------------------------\n",
    "demo = gr.Interface(\n",
    "    fn=predict,\n",
    "    inputs=gr.Image(type=\"pil\"),\n",
    "    outputs=[\n",
    "        gr.Image(type=\"pil\", label=\"Detección IDs\"),\n",
    "        gr.Gallery(label=\"Crops con OCR\", columns=2, height=\"auto\"),\n",
    "        gr.JSON(label=\"Resultados OCR en crops\"),\n",
    "        gr.Textbox(label=\"OCR en imagen completa\"),\n",
    "        gr.Markdown(label=\"Resumen final\"),\n",
    "    ],\n",
    "    title=\"Container Character Classification\",\n",
    "    description=\"Comparativa de detección YOLO y OCR (EasyOCR) en imagen completa y crops.\"\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
