{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fd280d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import paddle\n",
    "import torch\n",
    "from PIL import Image\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from paddleocr import PaddleOCR\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce633be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gpu_available = paddle.device.is_compiled_with_cuda()\n",
    "#print(\"GPU available:\", gpu_available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7d40ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mCreating model: ('PP-LCNet_x1_0_doc_ori', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/gnz/.paddlex/official_models/PP-LCNet_x1_0_doc_ori`.\u001b[0m\n",
      "\u001b[32mCreating model: ('UVDoc', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/gnz/.paddlex/official_models/UVDoc`.\u001b[0m\n",
      "\u001b[32mCreating model: ('PP-LCNet_x1_0_textline_ori', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/gnz/.paddlex/official_models/PP-LCNet_x1_0_textline_ori`.\u001b[0m\n",
      "\u001b[32mCreating model: ('PP-OCRv5_server_det', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/gnz/.paddlex/official_models/PP-OCRv5_server_det`.\u001b[0m\n",
      "\u001b[32mCreating model: ('en_PP-OCRv5_mobile_rec', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/gnz/.paddlex/official_models/en_PP-OCRv5_mobile_rec`.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ConfiguraciÃ³n\n",
    "CONF_THRESHOLD = 0.25\n",
    "PADDING = 15\n",
    "CLASSES = [\"cn-11s\", \"cn-4\", \"cn-7\", \"iso-type\"]\n",
    "WHITELIST_PATTERN = re.compile(r'^[A-Z0-9]+$')\n",
    "CUDA_VISIBLE_DEVICES = 0  # Cambia a -1 para CPU, 0 para la primera GPU, etc.\n",
    "\n",
    "# Cargar modelos\n",
    "# -------------------\n",
    "yolo_model = YOLO(\"/home/gnz/GitHub/yolo11_container/runs/detect/train3/weights/best.pt\")\n",
    "\n",
    "# PaddleOCR inicializado (puedes ajustar lang si necesitas chino, inglÃ©s, etc.)\n",
    "ocr_model = PaddleOCR(use_textline_orientation=True, lang=\"en\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68f3dc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.193 ðŸš€ Python-3.12.3 torch-2.8.0+cu128 CPU (13th Gen Intel Core(TM) i7-13620H)\n",
      "Setup complete âœ… (16 CPUs, 8.2 GB RAM, 112.8/1006.9 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a17b49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 cn-11, 1 iso-type, 406.2ms\n",
      "Speed: 36.3ms preprocess, 406.2ms inference, 37.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cn-11s, 1 iso-type, 342.6ms\n",
      "Speed: 8.3ms preprocess, 342.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cn-11s, 1 iso-type, 337.8ms\n",
      "Speed: 5.0ms preprocess, 337.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 cn-11, 1 iso-type, 371.4ms\n",
      "Speed: 4.8ms preprocess, 371.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "def crop_with_padding(image, xyxy, padding=PADDING):\n",
    "    x1, y1, x2, y2 = map(int, xyxy)\n",
    "    h, w = image.shape[:2]\n",
    "    x1 = max(x1 - padding, 0)\n",
    "    y1 = max(y1 - padding, 0)\n",
    "    x2 = min(x2 + padding, w)\n",
    "    y2 = min(y2 + padding, h)\n",
    "    return image[y1:y2, x1:x2]\n",
    "\n",
    "def run_ocr(ocr, container_image):\n",
    "    \"\"\"Corre OCR y devuelve texto filtrado (API moderna PaddleOCR).\"\"\"\n",
    "    result_ocr = ocr.predict(cv2.cvtColor(container_image, cv2.COLOR_BGR2RGB))\n",
    "    if not result_ocr or not result_ocr[0][\"rec_texts\"]:\n",
    "        return \"\"\n",
    "    \n",
    "    texts = result_ocr[0][\"rec_texts\"]\n",
    "    text_concat = ''.join(texts)\n",
    "    \n",
    "    # Filtrar por whitelist\n",
    "    output_text = ''.join([t for t in text_concat if WHITELIST_PATTERN.fullmatch(t)])\n",
    "    return output_text\n",
    "\n",
    "\n",
    "def draw_results(image, xyxy, class_name):\n",
    "    \"\"\"Dibuja solo el rectÃ¡ngulo y la etiqueta de la clase.\"\"\"\n",
    "    x1, y1, x2, y2 = map(int, xyxy)\n",
    "    cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    cv2.putText(\n",
    "        image,\n",
    "        class_name,\n",
    "        (x1, y1 - 5),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        0.8,\n",
    "        (0, 0, 0),\n",
    "        2\n",
    "    )\n",
    "\n",
    "\n",
    "# -------------------\n",
    "# Inference principal\n",
    "# -------------------\n",
    "def inference(img, conf_threshold=CONF_THRESHOLD):\n",
    "    \"\"\"\n",
    "    Procesa una imagen con YOLO + OCR y devuelve:\n",
    "    - Imagen anotada (PIL)\n",
    "    - Lista de resultados con clase, texto y confianza\n",
    "    \"\"\"\n",
    "    # Convertir a BGR para OpenCV\n",
    "    image = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
    "    detections_info = []\n",
    "\n",
    "    # Paso YOLO\n",
    "    results = yolo_model(image)\n",
    "\n",
    "    for result in results:\n",
    "        for cls_idx, cls_name in enumerate(CLASSES):\n",
    "            indices = (result.boxes.cls == cls_idx).nonzero(as_tuple=True)[0]\n",
    "\n",
    "            for idx in indices:\n",
    "                conf = result.boxes.conf[idx].item()\n",
    "                if conf < conf_threshold:\n",
    "                    continue\n",
    "\n",
    "                xyxy = result.boxes.xyxy[idx].squeeze().tolist()\n",
    "                plate_image = crop_with_padding(image, xyxy)\n",
    "                output_text = run_ocr(ocr_model, plate_image)\n",
    "\n",
    "                detections_info.append({\n",
    "                    \"class\": cls_name,\n",
    "                    \"text\": output_text,\n",
    "                    \"confidence\": conf\n",
    "                })\n",
    "\n",
    "                draw_results(image, xyxy, cls_name)\n",
    "\n",
    "\n",
    "    # Convertir a PIL para compatibilidad con Gradio\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    im_show = Image.fromarray(image_rgb)\n",
    "\n",
    "    return im_show, detections_info\n",
    "\n",
    "# -------------------\n",
    "# Gradio UI\n",
    "# -------------------\n",
    "title = \"YOLO + OCR Contenedor\"\n",
    "description = \"\"\"\n",
    "- Demo de detecciÃ³n de cÃ³digos de contenedores con YOLO + PaddleOCR.\n",
    "- Clases soportadas: **cn-11s, cn-4, cn-7, iso-type**.\n",
    "- Se devuelve la imagen anotada y un diccionario con clase, OCR y confianza.\n",
    "\"\"\"\n",
    "\n",
    "css = \".output_image, .input_image {height: 40rem !important; width: 100% !important;}\"\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=inference,\n",
    "    inputs=gr.Image(type=\"pil\", label=\"Input\"),\n",
    "    outputs=[\n",
    "        gr.Image(type=\"pil\", label=\"Output\"),\n",
    "        gr.JSON(label=\"Resultados\")\n",
    "    ],\n",
    "    title=title,\n",
    "    description=description,\n",
    "    # examples=examples,\n",
    "    cache_examples=False,\n",
    "    css=css\n",
    ")\n",
    "\n",
    "demo.launch(debug=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
