{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2fd280d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import paddle\n",
    "import torch\n",
    "from PIL import Image\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from paddleocr import PaddleOCR\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce633be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: False\n"
     ]
    }
   ],
   "source": [
    "gpu_available = paddle.device.is_compiled_with_cuda()\n",
    "print(\"GPU available:\", gpu_available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a824649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 3080 Ti\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f7d40ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mCreating model: ('PP-LCNet_x1_0_doc_ori', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/gonzadzz/.paddlex/official_models/PP-LCNet_x1_0_doc_ori`.\u001b[0m\n",
      "\u001b[32mCreating model: ('UVDoc', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/gonzadzz/.paddlex/official_models/UVDoc`.\u001b[0m\n",
      "\u001b[32mCreating model: ('PP-LCNet_x1_0_textline_ori', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/gonzadzz/.paddlex/official_models/PP-LCNet_x1_0_textline_ori`.\u001b[0m\n",
      "\u001b[32mCreating model: ('PP-OCRv5_server_det', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/gonzadzz/.paddlex/official_models/PP-OCRv5_server_det`.\u001b[0m\n",
      "\u001b[32mCreating model: ('en_PP-OCRv5_mobile_rec', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/gonzadzz/.paddlex/official_models/en_PP-OCRv5_mobile_rec`.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ConfiguraciÃ³n\n",
    "CONF_THRESHOLD = 0.5\n",
    "PADDING = 15\n",
    "CLASSES = [\"cn-11s\", \"cn-4\", \"cn-7\", \"iso-type\"]\n",
    "WHITELIST_PATTERN = re.compile(r'^[A-Z0-9]+$')\n",
    "\n",
    "# Cargar modelos\n",
    "# -------------------\n",
    "yolo_model = YOLO(\"/home/gonzadzz/GitHub/yolo11_container/runs/detect/train2/weights/best.pt\")\n",
    "\n",
    "# PaddleOCR inicializado (puedes ajustar lang si necesitas chino, inglÃ©s, etc.)\n",
    "ocr_model = PaddleOCR(use_textline_orientation=True, lang=\"en\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68f3dc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.193 ðŸš€ Python-3.12.3 torch-2.8.0+cu128 CUDA:0 (NVIDIA GeForce RTX 3080 Ti, 12288MiB)\n",
      "Setup complete âœ… (16 CPUs, 21.3 GB RAM, 128.2/1006.9 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a17b49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 cn-11s, 2 iso-types, 60.3ms\n",
      "Speed: 2.7ms preprocess, 60.3ms inference, 10.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cn-11s, 1 iso-type, 71.0ms\n",
      "Speed: 3.4ms preprocess, 71.0ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 cn-11, 1 iso-type, 119.7ms\n",
      "Speed: 2.7ms preprocess, 119.7ms inference, 20.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "def crop_with_padding(image, xyxy, padding=PADDING):\n",
    "    x1, y1, x2, y2 = map(int, xyxy)\n",
    "    h, w = image.shape[:2]\n",
    "    x1 = max(x1 - padding, 0)\n",
    "    y1 = max(y1 - padding, 0)\n",
    "    x2 = min(x2 + padding, w)\n",
    "    y2 = min(y2 + padding, h)\n",
    "    return image[y1:y2, x1:x2]\n",
    "\n",
    "def run_ocr(ocr, container_image):\n",
    "    \"\"\"Corre OCR y devuelve texto filtrado (API moderna PaddleOCR).\"\"\"\n",
    "    result_ocr = ocr.predict(cv2.cvtColor(container_image, cv2.COLOR_BGR2RGB))\n",
    "    if not result_ocr or not result_ocr[0][\"rec_texts\"]:\n",
    "        return \"\"\n",
    "    \n",
    "    texts = result_ocr[0][\"rec_texts\"]\n",
    "    text_concat = ''.join(texts)\n",
    "    \n",
    "    # Filtrar por whitelist\n",
    "    output_text = ''.join([t for t in text_concat if WHITELIST_PATTERN.fullmatch(t)])\n",
    "    return output_text\n",
    "\n",
    "\n",
    "def draw_results(image, xyxy, class_name):\n",
    "    \"\"\"Dibuja solo el rectÃ¡ngulo y la etiqueta de la clase.\"\"\"\n",
    "    x1, y1, x2, y2 = map(int, xyxy)\n",
    "    cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    cv2.putText(\n",
    "        image,\n",
    "        class_name,\n",
    "        (x1, y1 - 5),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        0.8,\n",
    "        (0, 0, 0),\n",
    "        2\n",
    "    )\n",
    "\n",
    "\n",
    "# -------------------\n",
    "# Inference principal\n",
    "# -------------------\n",
    "def inference(img, conf_threshold=CONF_THRESHOLD):\n",
    "    \"\"\"\n",
    "    Procesa una imagen con YOLO + OCR y devuelve:\n",
    "    - Imagen anotada (PIL)\n",
    "    - Lista de resultados con clase, texto y confianza\n",
    "    \"\"\"\n",
    "    # Convertir a BGR para OpenCV\n",
    "    image = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
    "    detections_info = []\n",
    "\n",
    "    # Paso YOLO\n",
    "    results = yolo_model(image, device=0)\n",
    "\n",
    "    for result in results:\n",
    "        for cls_idx, cls_name in enumerate(CLASSES):\n",
    "            indices = (result.boxes.cls == cls_idx).nonzero(as_tuple=True)[0]\n",
    "\n",
    "            for idx in indices:\n",
    "                conf = result.boxes.conf[idx].item()\n",
    "                if conf < conf_threshold:\n",
    "                    continue\n",
    "\n",
    "                xyxy = result.boxes.xyxy[idx].squeeze().tolist()\n",
    "                plate_image = crop_with_padding(image, xyxy)\n",
    "                output_text = run_ocr(ocr_model, plate_image)\n",
    "\n",
    "                detections_info.append({\n",
    "                    \"class\": cls_name,\n",
    "                    \"text\": output_text,\n",
    "                    \"confidence\": conf\n",
    "                })\n",
    "\n",
    "                draw_results(image, xyxy, cls_name)\n",
    "\n",
    "\n",
    "    # Convertir a PIL para compatibilidad con Gradio\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    im_show = Image.fromarray(image_rgb)\n",
    "\n",
    "    return im_show, detections_info\n",
    "\n",
    "# -------------------\n",
    "# Gradio UI\n",
    "# -------------------\n",
    "title = \"YOLO + OCR Contenedor\"\n",
    "description = \"\"\"\n",
    "- Demo de detecciÃ³n de cÃ³digos de contenedores con YOLO + PaddleOCR.\n",
    "- Clases soportadas: **cn-11s, cn-4, cn-7, iso-type**.\n",
    "- Se devuelve la imagen anotada y un diccionario con clase, OCR y confianza.\n",
    "\"\"\"\n",
    "\n",
    "css = \".output_image, .input_image {height: 40rem !important; width: 100% !important;}\"\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=inference,\n",
    "    inputs=gr.Image(type=\"pil\", label=\"Input\"),\n",
    "    outputs=[\n",
    "        gr.Image(type=\"pil\", label=\"Output\"),\n",
    "        gr.JSON(label=\"Resultados\")\n",
    "    ],\n",
    "    title=title,\n",
    "    description=description,\n",
    "    # examples=examples,\n",
    "    cache_examples=False,\n",
    "    css=css\n",
    ")\n",
    "\n",
    "demo.launch(debug=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
