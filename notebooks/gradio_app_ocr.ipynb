{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59eb0bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7864\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 cn-11, 1 iso-type, 57.1ms\n",
      "Speed: 4.6ms preprocess, 57.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 256x640 (no detections), 48.1ms\n",
      "Speed: 1.1ms preprocess, 48.1ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 128x640 2 0s, 1 3, 1 4, 1 7, 1 9, 1 T, 1 U, 71.9ms\n",
      "Speed: 1.5ms preprocess, 71.9ms inference, 2.8ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "0: 384x640 1 cn-11, 1 iso-type, 89.4ms\n",
      "Speed: 4.8ms preprocess, 89.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 640x96 1 1, 2 2s, 1 G, 72.3ms\n",
      "Speed: 0.8ms preprocess, 72.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 96)\n",
      "\n",
      "0: 640x64 1 1, 1 2, 1 3, 1 4, 2 8s, 1 9, 1 A, 63.4ms\n",
      "Speed: 0.7ms preprocess, 63.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 64)\n",
      "\n",
      "0: 384x640 1 cn-11, 1 iso-type, 71.5ms\n",
      "Speed: 7.3ms preprocess, 71.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 128x640 1 0, 1 1, 1 2, 1 3, 1 4, 1 5, 1 6, 1 L, 1 T, 105.2ms\n",
      "Speed: 1.1ms preprocess, 105.2ms inference, 2.1ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "0: 384x640 (no detections), 41.4ms\n",
      "Speed: 2.3ms preprocess, 41.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 cn-4, 1 cn-7, 51.7ms\n",
      "Speed: 2.7ms preprocess, 51.7ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.5ms\n",
      "Speed: 1.9ms preprocess, 11.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 224x640 2 0s, 2 1s, 1 6, 1 8, 67.0ms\n",
      "Speed: 1.2ms preprocess, 67.0ms inference, 1.4ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 384x640 1 cn-11, 1 iso-type, 64.7ms\n",
      "Speed: 2.4ms preprocess, 64.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 640x64 1 0, 1 1, 1 2, 2 4s, 1 5, 1 9, 1 U, 99.2ms\n",
      "Speed: 1.1ms preprocess, 99.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 64)\n",
      "\n",
      "0: 640x96 1 1, 1 2, 1 4, 1 G, 66.7ms\n",
      "Speed: 1.0ms preprocess, 66.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 96)\n",
      "\n",
      "0: 384x640 2 cn-11s, 74.2ms\n",
      "Speed: 3.7ms preprocess, 74.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 128x640 2 0s, 1 1, 1 6, 2 7s, 1 8, 1 S, 1 U, 76.3ms\n",
      "Speed: 1.0ms preprocess, 76.3ms inference, 3.7ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "0: 384x640 1 cn-4, 1 cn-7, 1 iso-type, 65.0ms\n",
      "Speed: 7.4ms preprocess, 65.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 416x640 (no detections), 84.7ms\n",
      "Speed: 2.0ms preprocess, 84.7ms inference, 0.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "0: 224x640 1 0, 1 1, 1 4, 1 6, 2 9s, 85.6ms\n",
      "Speed: 0.9ms preprocess, 85.6ms inference, 5.5ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 320x640 1 5, 67.7ms\n",
      "Speed: 1.2ms preprocess, 67.7ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 384x640 1 cn-11, 1 iso-type, 30.6ms\n",
      "Speed: 2.5ms preprocess, 30.6ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 160x640 2 0s, 1 3, 1 5, 1 6, 2 7s, 1 D, 1 R, 2 Ts, 73.4ms\n",
      "Speed: 1.7ms preprocess, 73.4ms inference, 2.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 448x640 (no detections), 89.2ms\n",
      "Speed: 1.6ms preprocess, 89.2ms inference, 0.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 384x640 1 cn-11, 1 iso-type, 95.3ms\n",
      "Speed: 2.5ms preprocess, 95.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 128x640 4 2s, 1 3, 1 6, 1 9, 1 M, 1 U, 1 X, 118.6ms\n",
      "Speed: 1.7ms preprocess, 118.6ms inference, 2.0ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.6ms\n",
      "Speed: 1.1ms preprocess, 15.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 cn-11, 1 iso-type, 59.9ms\n",
      "Speed: 4.7ms preprocess, 59.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 640x64 1 0, 3 4s, 2 6s, 1 8, 1 H, 1 U, 69.6ms\n",
      "Speed: 0.7ms preprocess, 69.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 64)\n",
      "\n",
      "0: 640x128 1 1, 1 4, 1 5, 82.5ms\n",
      "Speed: 0.6ms preprocess, 82.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 128)\n",
      "\n",
      "0: 384x640 2 cn-11s, 1 iso-type, 77.5ms\n",
      "Speed: 7.1ms preprocess, 77.5ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.6ms\n",
      "Speed: 2.1ms preprocess, 14.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 416x640 (no detections), 74.4ms\n",
      "Speed: 2.1ms preprocess, 74.4ms inference, 0.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "0: 384x640 1 cn-11, 73.0ms\n",
      "Speed: 4.8ms preprocess, 73.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 128x640 1 3, 1 5, 1 6, 2 7s, 1 9, 1 S, 1 U, 74.1ms\n",
      "Speed: 1.0ms preprocess, 74.1ms inference, 2.0ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "0: 384x640 1 cn-4, 1 cn-7, 1 iso-type, 175.6ms\n",
      "Speed: 3.9ms preprocess, 175.6ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 320x640 (no detections), 85.8ms\n",
      "Speed: 1.3ms preprocess, 85.8ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 1, 14.8ms\n",
      "Speed: 2.1ms preprocess, 14.8ms inference, 5.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 192x640 2 0s, 3 4s, 1 6, 1 8, 88.0ms\n",
      "Speed: 1.3ms preprocess, 88.0ms inference, 1.5ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "0: 384x640 1 cn-11, 1 iso-type, 153.5ms\n",
      "Speed: 4.1ms preprocess, 153.5ms inference, 19.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 640x96 1 1, 2 2s, 1 G, 78.6ms\n",
      "Speed: 1.1ms preprocess, 78.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 96)\n",
      "\n",
      "0: 640x64 1 1, 1 2, 1 3, 1 4, 2 8s, 1 9, 1 A, 82.8ms\n",
      "Speed: 2.3ms preprocess, 82.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 64)\n",
      "\n",
      "0: 384x640 1 cn-11, 287.8ms\n",
      "Speed: 3.1ms preprocess, 287.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 640x96 1 1, 2 3s, 1 4, 1 5, 1 7, 1 8, 1 9, 1 M, 1 O, 1 U, 74.5ms\n",
      "Speed: 1.8ms preprocess, 74.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 96)\n",
      "\n",
      "0: 384x640 1 cn-11, 1 iso-type, 11.7ms\n",
      "Speed: 2.1ms preprocess, 11.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 160x640 1 0, 1 2, 1 3, 1 5, 3 6s, 1 L, 2 Os, 1 T, 101.2ms\n",
      "Speed: 1.5ms preprocess, 101.2ms inference, 13.7ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 416x640 1 5, 70.8ms\n",
      "Speed: 1.1ms preprocess, 70.8ms inference, 1.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "import easyocr\n",
    "import re\n",
    "\n",
    "\n",
    "# Cargar modelos\n",
    "# ids_model = YOLO(\"/home/gnz/GitHub/yolo11_container/YOLO_IDs/ID_YOLO_container/weights/best.pt\")\n",
    "ids_model = YOLO(\"/home/gonzadzz/GitHub/yolo11_container/YOLO_IDs/ID_YOLO_container/weights/best.pt\")\n",
    "# char_model = YOLO(\"/home/gnz/GitHub/yolo11_container/YOLO_Characters/Character_YOLO_container_finetune_large/weights/best.pt\")\n",
    "char_model = YOLO(\"/home/gonzadzz/GitHub/yolo11_container/YOLO_Characters/Character_YOLO_container_finetune_extra_large_phase2/weights/best.pt\")\n",
    "# Inicializar EasyOCR\n",
    "ocr_model = easyocr.Reader(['en','es'])\n",
    "\n",
    "# Reglas RegEx para validación\n",
    "rules = {\n",
    "    \"code-container\": {\"attribute\": \"code-container\", \"regex\": r\"^[A-Z]{4}\\d{7}$\"},\n",
    "    \"cn-11\": {\"attribute\": \"cn-11\", \"regex\": r\"^[A-Z]{4}\\d{7}$\"},\n",
    "    \"cn-4\": {\"attribute\": \"cn-4\", \"regex\": r\"^[A-Z]{4}$\"},\n",
    "    \"cn-7\": {\"attribute\": \"cn-7\", \"regex\": r\"^\\d{7}$\"},\n",
    "    \"iso-type\": {\"attribute\": \"iso-type\", \"regex\": r\"^.{2}[A-Z0-9]{2}$\"}  # ajustado a ISO tipo\n",
    "}\n",
    "\n",
    "# Reglas de validación\n",
    "def parse_detecciones(detecciones, rules):\n",
    "    parsed = {}\n",
    "    for key, value in detecciones.items():\n",
    "        if key in rules:\n",
    "            attr = rules[key][\"attribute\"]\n",
    "            pattern = rules[key][\"regex\"]\n",
    "\n",
    "            # Validar con regex\n",
    "            match = bool(re.match(pattern, value))\n",
    "\n",
    "            # Resultado estructurado para Gradio JSON\n",
    "            parsed[attr] = {\n",
    "                \"value\": value,\n",
    "                \"valid\": \"✔️\" if match else \"❌\"\n",
    "            }\n",
    "    return parsed\n",
    "\n",
    "def calculate_check_digit(container_code: str) -> str | None:\n",
    "    \"\"\"\n",
    "    Calcula o valida el dígito de check digit de un código de contenedor ISO 6346.\n",
    "    \n",
    "    - Si el código tiene 10 caracteres → calcula el dígito y devuelve el código completo (11).\n",
    "    - Si el código tiene 11 caracteres → valida el dígito, si es correcto devuelve el mismo,\n",
    "      si es incorrecto devuelve el código corregido.\n",
    "    - Si el código tiene más de 11 → toma los primeros 10, calcula el dígito y devuelve esos 11.\n",
    "    - Si los primeros 4 caracteres no son letras, devuelve None.\n",
    "    \"\"\"\n",
    "    # Validar longitud mínima\n",
    "    if len(container_code) < 10:\n",
    "        return None\n",
    "\n",
    "    # Validar que los primeros 4 sean letras\n",
    "    if not container_code[:4].isalpha():\n",
    "        return None\n",
    "\n",
    "    # Tomar primeros 10 caracteres\n",
    "    code_10 = container_code[:10]\n",
    "\n",
    "    # Mapeo de letras a valores ISO 6346\n",
    "    letter_values = {\n",
    "        'A': 10, 'B': 12, 'C': 13, 'D': 14, 'E': 15, 'F': 16, 'G': 17, 'H': 18, 'I': 19, 'J': 20,\n",
    "        'K': 21, 'L': 23, 'M': 24, 'N': 25, 'O': 26, 'P': 27, 'Q': 28, 'R': 29, 'S': 30, 'T': 31,\n",
    "        'U': 32, 'V': 34, 'W': 35, 'X': 36, 'Y': 37, 'Z': 38\n",
    "    }\n",
    "\n",
    "    # Convertir a valores numéricos\n",
    "    values = []\n",
    "    for char in code_10:\n",
    "        if char.isalpha():\n",
    "            values.append(letter_values[char.upper()])\n",
    "        else:\n",
    "            values.append(int(char))\n",
    "\n",
    "    # Calcular suma ponderada con 2^(posición)\n",
    "    total = sum(val * (2 ** i) for i, val in enumerate(values))\n",
    "\n",
    "    # Resto módulo 11\n",
    "    check_digit = total % 11\n",
    "    if check_digit == 10:\n",
    "        check_digit = 0\n",
    "\n",
    "    # Caso 10 caracteres → devolver con check digit\n",
    "    if len(container_code) == 10:\n",
    "        return code_10 + str(check_digit)\n",
    "\n",
    "    # Caso 11 caracteres → validar o corregir\n",
    "    if len(container_code) == 11:\n",
    "        last_digit = container_code[10]\n",
    "        if last_digit.isdigit() and int(last_digit) == check_digit:\n",
    "            return container_code  # es válido\n",
    "        else:\n",
    "            # Corregir último carácter\n",
    "            return code_10 + str(check_digit)\n",
    "\n",
    "    # Caso más de 11 caracteres → recortar y recalcular\n",
    "    if len(container_code) > 11:\n",
    "        return code_10 + str(check_digit)\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "########################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "def predict(image):\n",
    "    detecciones_yolo = {}\n",
    "    detecciones_easy = {}\n",
    "    crops_con_labels = []\n",
    "    texto_reconstruido_imgs = []\n",
    "\n",
    "    # Variables auxiliares para armar code-container\n",
    "    cn11_code_yolo, cn4_code_yolo, cn7_code_yolo = None, None, None\n",
    "    cn11_code_easy, cn4_code_easy, cn7_code_easy = None, None, None\n",
    "\n",
    "    # 1. Detección con primer modelo (IDs)\n",
    "    results_id = ids_model.predict(image, conf=0.5)\n",
    "\n",
    "    # 1a. Recolectar todas las detecciones con sus confidences\n",
    "    detections = []\n",
    "    for box in results_id[0].boxes:\n",
    "        cls_id = int(box.cls[0].item())\n",
    "        cls_name = ids_model.names[cls_id]\n",
    "        conf = float(box.conf[0].item())\n",
    "        x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
    "        detections.append({\n",
    "            \"cls_name\": cls_name,\n",
    "            \"conf\": conf,\n",
    "            \"coords\": (x1, y1, x2, y2)\n",
    "        })\n",
    "\n",
    "    # 1b. Filtrar solo la detección de mayor confidence por clase\n",
    "    best_detections = {}\n",
    "    for det in detections:\n",
    "        cls_name = det[\"cls_name\"]\n",
    "        if cls_name not in best_detections or det[\"conf\"] > best_detections[cls_name][\"conf\"]:\n",
    "            best_detections[cls_name] = det\n",
    "\n",
    "    # Imagen con todas las bounding boxes originales\n",
    "    img_with_boxes = results_id[0].plot()\n",
    "    img_with_boxes_pil = Image.fromarray(img_with_boxes)\n",
    "\n",
    "    # 2. Procesar cada detección filtrada\n",
    "    for cls_name, det in best_detections.items():\n",
    "        x1, y1, x2, y2 = det[\"coords\"]\n",
    "        crop = image.crop((x1, y1, x2, y2))\n",
    "\n",
    "        # 2a. Pasar crop al modelo OCR (YOLO chars)\n",
    "        results_char = char_model.predict(crop, conf=0.5)\n",
    "        chars_detected = []\n",
    "\n",
    "        for cbox in results_char[0].boxes:\n",
    "            c_cls_id = int(cbox.cls[0].item())\n",
    "            c_cls_name = char_model.names[c_cls_id]\n",
    "            cx1, cy1, cx2, cy2 = cbox.xyxy[0].tolist()\n",
    "            char_crop = crop.crop((cx1, cy1, cx2, cy2))\n",
    "            chars_detected.append((cx1, cy1, c_cls_name, char_crop))\n",
    "\n",
    "        # 2b. Ordenar y concatenar caracteres para YOLO char\n",
    "        text_pred = \"\"\n",
    "        if cls_name in [\"cn-11\", \"iso-type\"]:\n",
    "            if crop.height > crop.width * 1.5:  # vertical\n",
    "                chars_detected = sorted(chars_detected, key=lambda x: x[1])\n",
    "            else:  # horizontal\n",
    "                chars_detected = sorted(chars_detected, key=lambda x: x[0])\n",
    "            text_pred = \"\".join([c[2] for c in chars_detected])\n",
    "        elif cls_name in [\"cn-4\", \"cn-7\"]:\n",
    "            chars_detected = sorted(chars_detected, key=lambda x: x[0])\n",
    "            text_pred = \"\".join([c[2] for c in chars_detected])\n",
    "\n",
    "        # Guardar detecciones YOLO\n",
    "        detecciones_yolo[cls_name] = text_pred\n",
    "        if cls_name == \"cn-11\":\n",
    "            cn11_code_yolo = text_pred\n",
    "        elif cls_name == \"cn-4\":\n",
    "            cn4_code_yolo = text_pred\n",
    "        elif cls_name == \"cn-7\":\n",
    "            cn7_code_yolo = text_pred\n",
    "\n",
    "        # 2c. Guardar crops anotados\n",
    "        crop_with_boxes = results_char[0].plot()\n",
    "        crops_con_labels.append(Image.fromarray(crop_with_boxes))\n",
    "\n",
    "        # 2d. EasyOCR\n",
    "        # Regla: cn-4 / cn-7 horizontales → OCR siempre sobre crop original\n",
    "        if cls_name in [\"cn-4\", \"cn-7\", \"cn-11\", \"iso-type\"] and crop.width > crop.height:\n",
    "            ocr_text = ocr_model.readtext(np.array(crop), detail=0)\n",
    "        else:\n",
    "            if chars_detected:\n",
    "                # Reconstrucción horizontal de chars\n",
    "                widths, heights = zip(*(c[3].size for c in chars_detected))\n",
    "                total_width = sum(widths)\n",
    "                max_height = max(heights)\n",
    "                new_img = Image.new(\"RGB\", (total_width, max_height), color=(0,0,0))\n",
    "                x_offset = 0\n",
    "                for _, _, _, char_crop in chars_detected:\n",
    "                    new_img.paste(char_crop, (x_offset,0))\n",
    "                    x_offset += char_crop.width\n",
    "                texto_reconstruido_imgs.append(new_img)\n",
    "\n",
    "                ocr_text = ocr_model.readtext(np.array(new_img), detail=0)\n",
    "            else:\n",
    "                # No hay chars detectados → OCR sobre crop original\n",
    "                ocr_text = ocr_model.readtext(np.array(crop), detail=0)\n",
    "\n",
    "        # Limpiar espacios y guardar en detecciones_easy\n",
    "        if ocr_text:\n",
    "            ocr_text_clean = \"\".join(ocr_text).replace(\" \", \"\")\n",
    "            ocr_text_clean = re.sub(r'[^A-Z0-9]', '', ocr_text_clean.upper())\n",
    "            detecciones_easy[cls_name] = ocr_text_clean\n",
    "            if cls_name == \"cn-11\":\n",
    "                cn11_code_easy = ocr_text_clean\n",
    "            elif cls_name == \"cn-4\":\n",
    "                cn4_code_easy = ocr_text_clean\n",
    "            elif cls_name == \"cn-7\":\n",
    "                cn7_code_easy = ocr_text_clean\n",
    "\n",
    "    # 3. Construir code-container YOLO\n",
    "    if cn11_code_yolo:\n",
    "        detecciones_yolo[\"code-container\"] = cn11_code_yolo\n",
    "    elif cn4_code_yolo and cn7_code_yolo:\n",
    "        detecciones_yolo[\"code-container\"] = cn4_code_yolo + cn7_code_yolo\n",
    "\n",
    "    # 4. Construir code-container EasyOCR\n",
    "    if cn11_code_easy:\n",
    "        detecciones_easy[\"code-container\"] = cn11_code_easy\n",
    "    elif cn4_code_easy and cn7_code_easy:\n",
    "        detecciones_easy[\"code-container\"] = cn4_code_easy + cn7_code_easy\n",
    "\n",
    "    # 5. Validar ambos\n",
    "    parsed_yolo = parse_detecciones(detecciones_yolo, rules)\n",
    "    parsed_easy = parse_detecciones(detecciones_easy, rules) if detecciones_easy else {}\n",
    "\n",
    "    # 6. Calcular validated_code_container para ambos\n",
    "    validated_yolo = None\n",
    "    validated_easy = None\n",
    "\n",
    "    if \"code-container\" in detecciones_yolo:\n",
    "        validated_yolo = calculate_check_digit(detecciones_yolo[\"code-container\"])\n",
    "\n",
    "    if \"code-container\" in detecciones_easy:\n",
    "        validated_easy = calculate_check_digit(detecciones_easy[\"code-container\"])\n",
    "\n",
    "    # 7. Armar salida final\n",
    "    salida_json = {\n",
    "        \"output_yolo_char\": detecciones_yolo,\n",
    "        \"output_easy_ocr\": detecciones_easy,\n",
    "        \"validation\": {\n",
    "            \"yolo_char\": parsed_yolo,\n",
    "            \"easy_ocr\": parsed_easy\n",
    "        },\n",
    "        \"validated_code_container\": {\n",
    "            \"yolo_char\": validated_yolo,\n",
    "            \"easy_ocr\": validated_easy\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return img_with_boxes_pil, crops_con_labels, texto_reconstruido_imgs, salida_json\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "# Interfaz de Gradio\n",
    "demo = gr.Interface(\n",
    "    fn=predict,\n",
    "    inputs=gr.Image(type=\"pil\"),\n",
    "    outputs=[\n",
    "        gr.Image(type=\"pil\", label=\"Detección IDs\"),\n",
    "        gr.Gallery(label=\"Crops con OCR\", columns=2, height=\"auto\"),\n",
    "        gr.Gallery(label=\"Texto reconstruido en renglón\", columns=1, height=\"auto\"),\n",
    "        gr.JSON(label=\"Resultados OCR\")\n",
    "    ],\n",
    "    title=\"Container OCR Detector\",\n",
    "    description=\"Detecta IDs de contenedores. Si hay clase cn-11 se usa como code-container; si no, se genera con cn-4 + cn-7.\"\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
